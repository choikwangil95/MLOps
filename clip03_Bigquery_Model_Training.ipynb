{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "054a31c9-5bef-4fe4-8492-fa867a5d9b5b",
   "metadata": {},
   "source": [
    "### 0. 필요한 Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1fc25-a5eb-4adb-b3b7-441b4ac5e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb3a599-4f57-42f5-bf60-8a57ee4080d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 07:38:19.486662: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 07:38:25.983104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-02-13 07:38:25.984693: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-02-13 07:38:25.984717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63350f37-94af-469c-a265-996b0402ea87",
   "metadata": {},
   "source": [
    "### 1. BigQuery Connector를 활용한 Pandas DataFrame 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d955c6d3-3ec1-4aad-baa1-d945e715eeeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following two lines are only necessary to run once.\n",
    "# Comment out otherwise for speed-up.\n",
    "from google.cloud.bigquery import Client, QueryJobConfig\n",
    "client = Client()\n",
    "\n",
    "query = \"\"\"WITH staging AS (\n",
    "    SELECT\n",
    "        STRUCT(\n",
    "            start_stn.name,\n",
    "            ST_GEOGPOINT(start_stn.longitude, start_stn.latitude) AS POINT,\n",
    "            start_stn.docks_count,\n",
    "            start_stn.install_date\n",
    "        ) AS starting,\n",
    "        STRUCT(\n",
    "            end_stn.name,\n",
    "            ST_GEOGPOINT(end_stn.longitude, end_stn.latitude) AS point,\n",
    "            end_stn.docks_count,\n",
    "            end_stn.install_date\n",
    "        ) AS ending,\n",
    "        STRUCT(\n",
    "            rental_id,\n",
    "            bike_id,\n",
    "            duration, --seconds\n",
    "            ST_DISTANCE(\n",
    "                ST_GEOGPOINT(start_stn.longitude, start_stn.latitude),\n",
    "                ST_GEOGPOINT(end_stn.longitude, end_stn.latitude)\n",
    "            ) AS distance, --meters\n",
    "            start_date,\n",
    "            end_date\n",
    "        ) AS bike\n",
    "        FROM `bigquery-public-data.london_bicycles.cycle_stations` AS start_stn\n",
    "        LEFT JOIN `bigquery-public-data.london_bicycles.cycle_hire` as b \n",
    "        ON start_stn.id = b.start_station_id\n",
    "        LEFT JOIN `bigquery-public-data.london_bicycles.cycle_stations` AS end_stn\n",
    "        ON end_stn.id = b.end_station_id\n",
    "        LIMIT 100000)\n",
    "\n",
    "SELECT * from STAGING\"\"\"\n",
    "job = client.query(query)\n",
    "df = job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d7c787-f99f-47b5-9a65-85cd1cbf10e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting</th>\n",
       "      <th>ending</th>\n",
       "      <th>bike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'name': 'Westbourne Grove, Bayswater', 'POINT...</td>\n",
       "      <td>{'name': 'Park Lane , Hyde Park', 'point': 'PO...</td>\n",
       "      <td>{'rental_id': 74377596, 'bike_id': 14110, 'dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'name': 'Westbourne Grove, Bayswater', 'POINT...</td>\n",
       "      <td>{'name': 'George Street, Marylebone', 'point':...</td>\n",
       "      <td>{'rental_id': 86024974, 'bike_id': 15856, 'dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'name': 'Westbourne Grove, Bayswater', 'POINT...</td>\n",
       "      <td>{'name': 'Collingham Gardens, Earl's Court', '...</td>\n",
       "      <td>{'rental_id': 96741475, 'bike_id': 9871, 'dura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'name': 'Westbourne Grove, Bayswater', 'POINT...</td>\n",
       "      <td>{'name': 'Limerston Street, West Chelsea', 'po...</td>\n",
       "      <td>{'rental_id': 52067778, 'bike_id': 1752, 'dura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'name': 'Westbourne Grove, Bayswater', 'POINT...</td>\n",
       "      <td>{'name': 'Seville Street, Knightsbridge', 'poi...</td>\n",
       "      <td>{'rental_id': 117308140, 'bike_id': 2765, 'dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>{'name': 'Westbourne Grove, Bayswater', 'POINT...</td>\n",
       "      <td>{'name': 'Albert Gate, Hyde Park', 'point': 'P...</td>\n",
       "      <td>{'rental_id': 59561760, 'bike_id': 2958, 'dura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>{'name': 'Westbourne Grove, Bayswater', 'POINT...</td>\n",
       "      <td>{'name': 'Albert Gate, Hyde Park', 'point': 'P...</td>\n",
       "      <td>{'rental_id': 84596956, 'bike_id': 242, 'durat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>{'name': 'Westbourne Grove, Bayswater', 'POINT...</td>\n",
       "      <td>{'name': 'Albert Gate, Hyde Park', 'point': 'P...</td>\n",
       "      <td>{'rental_id': 69875465, 'bike_id': 14638, 'dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>{'name': 'Westbourne Grove, Bayswater', 'POINT...</td>\n",
       "      <td>{'name': 'Albert Gate, Hyde Park', 'point': 'P...</td>\n",
       "      <td>{'rental_id': 112339479, 'bike_id': 73, 'durat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>{'name': 'Westbourne Grove, Bayswater', 'POINT...</td>\n",
       "      <td>{'name': 'Albert Gate, Hyde Park', 'point': 'P...</td>\n",
       "      <td>{'rental_id': 84624311, 'bike_id': 3621, 'dura...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                starting  \\\n",
       "0      {'name': 'Westbourne Grove, Bayswater', 'POINT...   \n",
       "1      {'name': 'Westbourne Grove, Bayswater', 'POINT...   \n",
       "2      {'name': 'Westbourne Grove, Bayswater', 'POINT...   \n",
       "3      {'name': 'Westbourne Grove, Bayswater', 'POINT...   \n",
       "4      {'name': 'Westbourne Grove, Bayswater', 'POINT...   \n",
       "...                                                  ...   \n",
       "99995  {'name': 'Westbourne Grove, Bayswater', 'POINT...   \n",
       "99996  {'name': 'Westbourne Grove, Bayswater', 'POINT...   \n",
       "99997  {'name': 'Westbourne Grove, Bayswater', 'POINT...   \n",
       "99998  {'name': 'Westbourne Grove, Bayswater', 'POINT...   \n",
       "99999  {'name': 'Westbourne Grove, Bayswater', 'POINT...   \n",
       "\n",
       "                                                  ending  \\\n",
       "0      {'name': 'Park Lane , Hyde Park', 'point': 'PO...   \n",
       "1      {'name': 'George Street, Marylebone', 'point':...   \n",
       "2      {'name': 'Collingham Gardens, Earl's Court', '...   \n",
       "3      {'name': 'Limerston Street, West Chelsea', 'po...   \n",
       "4      {'name': 'Seville Street, Knightsbridge', 'poi...   \n",
       "...                                                  ...   \n",
       "99995  {'name': 'Albert Gate, Hyde Park', 'point': 'P...   \n",
       "99996  {'name': 'Albert Gate, Hyde Park', 'point': 'P...   \n",
       "99997  {'name': 'Albert Gate, Hyde Park', 'point': 'P...   \n",
       "99998  {'name': 'Albert Gate, Hyde Park', 'point': 'P...   \n",
       "99999  {'name': 'Albert Gate, Hyde Park', 'point': 'P...   \n",
       "\n",
       "                                                    bike  \n",
       "0      {'rental_id': 74377596, 'bike_id': 14110, 'dur...  \n",
       "1      {'rental_id': 86024974, 'bike_id': 15856, 'dur...  \n",
       "2      {'rental_id': 96741475, 'bike_id': 9871, 'dura...  \n",
       "3      {'rental_id': 52067778, 'bike_id': 1752, 'dura...  \n",
       "4      {'rental_id': 117308140, 'bike_id': 2765, 'dur...  \n",
       "...                                                  ...  \n",
       "99995  {'rental_id': 59561760, 'bike_id': 2958, 'dura...  \n",
       "99996  {'rental_id': 84596956, 'bike_id': 242, 'durat...  \n",
       "99997  {'rental_id': 69875465, 'bike_id': 14638, 'dur...  \n",
       "99998  {'rental_id': 112339479, 'bike_id': 73, 'durat...  \n",
       "99999  {'rental_id': 84624311, 'bike_id': 3621, 'dura...  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23aee4-4fde-4668-a47d-b057fb7a905a",
   "metadata": {},
   "source": [
    "### 2. ML 학습에 활용할 데이터만 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1006a260-faae-47ef-9557-c11342f49b72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values = df['bike'].values\n",
    "duration = list(map(lambda a: a['duration'], values))\n",
    "distance = list(map(lambda a: a['distance'], values))\n",
    "dates = list(map(lambda a: a['start_date'], values))\n",
    "data = pd.DataFrame(data={'duration': duration, 'distance': distance, 'start_date':dates})\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1333c04-2b62-4278-9581-e74e2ff8b307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 98119 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   duration    98119 non-null  float64            \n",
      " 1   distance    98119 non-null  float64            \n",
      " 2   start_date  98119 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), float64(2)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a0eec-28c1-4f3a-9cdc-f94ea0420a14",
   "metadata": {},
   "source": [
    "### 3. 데이터 가공 \n",
    "1. strat_date(datetime64) -> weekday 추출, hour 추출, 기존 컬럼 제거\n",
    "2. duration -> minute 단위로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d184f85-bd18-4fac-b737-45279336c91f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['weekday'] = data['start_date'].apply(lambda a: a.weekday())\n",
    "data['hour'] = data['start_date'].apply(lambda a: a.time().hour)\n",
    "data = data.drop(columns=['start_date'])\n",
    "\n",
    "data['duration'] = data['duration'].apply(lambda x:float(x / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ad6d00-3f9a-4347-aa73-c682352dd15f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>distance</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2362.138868</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2512.004888</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2670.061603</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3387.911177</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2629.830365</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration     distance  weekday  hour\n",
       "0      64.0  2362.138868        5    13\n",
       "1      47.0  2512.004888        4    15\n",
       "2      30.0  2670.061603        4    10\n",
       "3      30.0  3387.911177        4    11\n",
       "4      30.0  2629.830365        2    19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f66eb1-e8d1-4972-b34a-63d8f19e355a",
   "metadata": {},
   "source": [
    "### 4. TensorFlow Model 생성\n",
    "1. dataset을 train, test set으로 나누기\n",
    "2. keras functional API를 활용해서, pandas dataframe을 tf.data.Dataset으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0daa7bbc-0a2c-43fa-b5b8-007c546e60a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, label, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop(label)\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4517b022-0d65-4fe5-9249-310c3bc5b9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7999979616588021\n",
      "0.20000203834119792\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * .8)\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:]\n",
    "\n",
    "print(len(train_data)/len(data))\n",
    "print(len(val_data)/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21477248-bce0-4008-9584-d0982ec3849d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 07:49:01.072289: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-02-13 07:49:01.073418: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-02-13 07:49:01.073485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-20240213-161422): /proc/driver/nvidia/version does not exist\n",
      "2024-02-13 07:49:01.080866: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = df_to_dataset(train_data, 'duration')\n",
    "validation_dataset = df_to_dataset(val_data, 'duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306fcb6e-24d7-4b87-b387-2dfc8fa1abef",
   "metadata": {},
   "source": [
    "3. model layer를 생성\n",
    " - Normalization layer : distance\n",
    " - CategoryEncoding layer, IntegerLookup layer : weekday, hour\n",
    " - Input layer를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af713cda-b402-402e-88f7-4cd9e9c5feb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for our feature.\n",
    "  normalizer = tf.keras.layers.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  index = tf.keras.layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Create a Discretization for our integer indices.\n",
    "  encoder = tf.keras.layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "  # layer so we can use them, or include them in the functional model later.\n",
    "  return lambda feature: encoder(index(feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e59812fb-4f7c-48ce-98fd-d689710ef60b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Keras input layer for each feature\n",
    "numeric_col = tf.keras.Input(shape=(1,), name='distance')\n",
    "hour_col = tf.keras.Input(shape=(1,), name='hour', dtype='int64')\n",
    "weekday_col = tf.keras.Input(shape=(1,), name='weekday', dtype='int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3707e44-d892-4661-9a58-c9b57fd1ad73",
   "metadata": {},
   "source": [
    "4. Layer 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19e2ee11-b23c-434c-8d94-b1c6bb71ab8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Pass 'distance' input to normalization layer\n",
    "normalization_layer = get_normalization_layer('distance', train_dataset)\n",
    "encoded_numeric_col = normalization_layer(numeric_col)\n",
    "all_inputs.append(numeric_col)\n",
    "encoded_features.append(encoded_numeric_col)\n",
    "\n",
    "# Pass 'hour' input to category encoding layer\n",
    "encoding_layer = get_category_encoding_layer('hour', train_dataset, dtype='int64')\n",
    "encoded_hour_col = encoding_layer(hour_col)\n",
    "all_inputs.append(hour_col)\n",
    "encoded_features.append(encoded_hour_col)\n",
    "\n",
    "# Pass 'weekday' input to category encoding layer\n",
    "encoding_layer = get_category_encoding_layer('weekday', train_dataset, dtype='int64')\n",
    "encoded_weekday_col = encoding_layer(weekday_col)\n",
    "all_inputs.append(weekday_col)\n",
    "encoded_features.append(encoded_weekday_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2220600d-3ab1-4394-b9ca-08ee017e7fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(all_features)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3e2543c-c650-4eea-8950-f0ba42161ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_logarithmic_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12808e54-9a86-4835-b925-6cddafb6fb67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7e849-352b-493d-8ab1-b4818e064849",
   "metadata": {},
   "source": [
    "### 5. TensorFlow Model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76bdf177-1a8b-48c2-8026-e276cdc490c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2453/2453 [==============================] - 7s 2ms/step - loss: 0.7801 - val_loss: 0.4742\n",
      "Epoch 2/2\n",
      "2453/2453 [==============================] - 5s 2ms/step - loss: 0.4286 - val_loss: 0.4563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdc38ff65c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data = validation_dataset, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fb15c-7859-40a7-ac62-96034c33597f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
